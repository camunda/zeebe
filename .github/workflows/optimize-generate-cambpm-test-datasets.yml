---
name: Optimize Generate Camunda BPM test datasets

on:
  workflow_dispatch:
    inputs:
      cambpm-version:
        description: |
          Camunda BPM version (default pom.xml):
        type: string
        required: false
      postgres-version:
        description: |
          Postgres version:
        type: string
        default: "11.2"
        required: true
      sql-dump-filename:
        description: |
          Output file name for SQL dump
        type: choice
        options:
        - optimize_data-e2e.sqlc
        - optimize_data-large.sqlc
        - optimize_data-medium.sqlc
        - optimize_data-stage.sqlc
        - optimize_data-dummy-workflow-test.sqlc
        default: optimize_data-large.sqlc
      use-e2e-presets:
        description: |
          Loads E2E test dataset presets
        type: boolean
        default: false
      process-instances-number:
        description: |
          Number of process instances (ignored if e2e presets)
        type: number
        default: 10000000
        required: true
      process-instances-adjust-dates:
        description: |
          Adjust process instance dates (ignored if e2e presets)
        type: boolean
        default: false
      process-definitions:
        description: |
          Comma-separated list of definitions (+ nb of versions) to generate (ignored if e2e presets)
        type: string
        required: false
      decision-instances-number:
        description: |
          Number of decision instances (ignored if e2e presets)
        type: number
        default: 100000
        required: true
      decision-definitions:
        description: |
          Comma-separated list of definitions (+ nb of versions) to generate (ignored if e2e presets)
        type: string
        required: false

jobs:
  generate-data:
    name: Generate Camunda BPM test datasets (output=${{ inputs.sql-dump-filename }}, use-e2e-presets=${{ inputs.use-e2e-presets }})
    concurrency:
      cancel-in-progress: true
      group: ${{ github.workflow }}-${{ inputs.sql-dump-filename }}
    runs-on: gcp-core-32-longrunning
    env:
      PGDATABASE: engine
      PGHOST: localhost
      PGPASSWORD: camunda
      PGUSER: camunda
      TZ: Europe/Berlin
      CAMBPM_VERSION: ${{ inputs.cambpm-version }}
      POSTGRES_VERSION: ${{ inputs.postgres-version }}
      SQL_DUMP_FILENAME: ${{ inputs.sql-dump-filename }}
      USE_E2E_PRESETS: ${{ inputs.use-e2e-presets }}
      PROCESS_INSTANCES_NUMBER: ${{ inputs.process-instances-number }}
      PROCESS_INSTANCES_ADJUST_DATES: ${{ inputs.process-instances-adjust-dates }}
      PROCESS_DEFINITIONS: ${{ inputs.process-definitions }}
      DECISION_INSTANCES_NUMBER: ${{ inputs.decision-instances-number }}
      DECISION_DEFINITIONS: ${{ inputs.decision-definitions }}
    steps:
    - uses: actions/checkout@v4
    - name: Read pom.xml
      id: pom-info
      if: env.CAMBPM_VERSION == ''
      uses: YunaBraska/java-info-action@main
    - name: Get cambpm version from pom.xml
      if: env.CAMBPM_VERSION == ''
      env:
        POM_XML_CAMBPM_VERSION: ${{ steps.pom-info.outputs.x_camunda_engine_version }}
      run: |
        {
          echo CAMBPM_VERSION=${POM_XML_CAMBPM_VERSION}
        } | tee -a $GITHUB_ENV
    - name: Login to Harbor registry
      uses: ./.github/actions/login-registry
      with:
        secrets: ${{ toJSON(secrets) }}
    - name: Import secrets
      id: secrets
      uses: hashicorp/vault-action@v3
      with:
        url: ${{ secrets.VAULT_ADDR }}
        method: approle
        roleId: ${{ secrets.VAULT_ROLE_ID }}
        secretId: ${{ secrets.VAULT_SECRET_ID }}
        secrets: |
          secret/data/products/optimize/ci/camunda-optimize CI_SERVICE_ACCOUNT;
    - uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ steps.secrets.outputs.CI_SERVICE_ACCOUNT }}
    - uses: google-github-actions/setup-gcloud@v2
    - name: Setup PostgreSQL client
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client
      shell: bash
    - name: Setup Maven
      uses: ./.github/actions/setup-maven
      with:
          secrets: ${{ toJSON(secrets) }}
          java-version: 17
          distribution: adopt
    - name: Setup host path volumes
      run: |
        mkdir -p ${RUNNER_TEMP}/cambpm/{logs,pgdata}
        # cambpm ee docker image needs write permissions on the logs directory
        sudo chown 1000 ${RUNNER_TEMP}/cambpm/logs
      shell: bash
    - name: Start container services
      uses: ./.github/actions/compose
      with:
        compose_file: ${{ github.workspace }}/.github/actions/compose/docker-compose.campbpm-data-generation.yml
        project_name: cambpm
    - name: Install qa/data-generation
      uses: ./.github/actions/run-maven
      with:
        parameters: >-
          -pl qa/data-generation -am clean install -DskipTests -Dskip.docker -Dskip.fe.build
    # cannot use actions/run-maven as quotes in exec args are badly escaped
    - name: Exec qa/data-generation (use-e2e-presets=${{ inputs.use-e2e-presets }})
      env:
        EXEC_ARGS: >-
          --processDefinitions "${{ env.PROCESS_DEFINITIONS }}"
          --numberOfProcessInstances "${{ env.PROCESS_INSTANCES_NUMBER }}"
          --numberOfDecisionInstances "${{ env.DECISION_INSTANCES_NUMBER }}"
          --decisionDefinitions "${{ env.DECISION_DEFINITIONS }}"
          --adjustProcessInstanceDates "${{ env.PROCESS_INSTANCES_ADJUST_DATES }}"
          --startDate "03/01/2018" --endDate "03/01/2020"
          --jdbcDriver "org.postgresql.Driver"
          --dbUrl "jdbc:postgresql://localhost:5432/engine"
          --dbUser "${{ env.PGUSER }}" --dbPassword "${{ env.PGPASSWORD }}"
        LIMITS_CPU: 2
      run: |
        set -x
        if [ "$USE_E2E_PRESETS" = true ]; then
          EXEC_ARGS=$(cat client/e2e_presets.json | jq -r 'to_entries | map("--" + .key + " " + (.value | tostring)) | .[]' | tr '\n' ' ')
        fi
        mvn -T1C -B -f qa/data-generation exec:java -Dexec.args="$EXEC_ARGS" --fail-at-end -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn
      shell: bash
    - name: Dump data from PostgreSQL service
      id: data
      run: |
        # Get metadata
        expected_number_of_process_instances=$(psql -q -A -t -c "select count(*) from act_hi_procinst;")
        expected_number_of_activity_instances=$(psql -q -A -t -c "select count(*) from act_hi_actinst;")
        expected_number_of_user_tasks=$(psql -q -A -t -c "select count(*) as total from act_hi_taskinst;")
        expected_number_of_variables=$(psql -q -A -t -c "select count(*) from act_hi_varinst where CASE_INST_ID_ is null;")
        expected_number_of_decision_instances=$(psql -q -A -t -c "select count(*) from act_hi_decinst;")

        # Dump database
        pg_dump -n public --format=c --file="./${SQL_DUMP_FILENAME}" engine

        {
          echo expected-number-of-process-instances=$expected_number_of_process_instances
          echo expected-number-of-activity-instances=$expected_number_of_activity_instances
          echo expected-number-of-user-tasks=$expected_number_of_user_tasks
          echo expected-number-of-variables=$expected_number_of_variables
          echo expected-number-of-decision-instances=$expected_number_of_decision_instances
        } | tee -a $GITHUB_OUTPUT
      shell: bash
    - name: Upload data
      env:
        EXPECTED_NUMBER_OF_PROCESS_INSTANCES: ${{ steps.data.outputs.expected-number-of-process-instances }}
        EXPECTED_NUMBER_OF_ACTIVITY_INSTANCES: ${{ steps.data.outputs.expected-number-of-activity-instances }}
        EXPECTED_NUMBER_OF_USER_TASKS: ${{ steps.data.outputs.expected-number-of-user-tasks }}
        EXPECTED_NUMBER_OF_VARIABLES: ${{ steps.data.outputs.expected-number-of-variables }}
        EXPECTED_NUMBER_OF_DECISION_INSTANCES: ${{ steps.data.outputs.expected-number-of-decision-instances }}
      run: |
        if [ "$USE_E2E_PRESETS" = true ]; then
          PROCESS_INSTANCES_NUMBER=$(jq -r .numberOfProcessInstances client/e2e_presets.json)
        fi
        gsutil \
          -h "x-goog-meta-NUM_INSTANCES:${PROCESS_INSTANCES_NUMBER}" \
          -h "x-goog-meta-EXPECTED_NUMBER_OF_PROCESS_INSTANCES:${EXPECTED_NUMBER_OF_PROCESS_INSTANCES}" \
          -h "x-goog-meta-EXPECTED_NUMBER_OF_ACTIVITY_INSTANCES:${EXPECTED_NUMBER_OF_ACTIVITY_INSTANCES}" \
          -h "x-goog-meta-EXPECTED_NUMBER_OF_USER_TASKS:${EXPECTED_NUMBER_OF_USER_TASKS}" \
          -h "x-goog-meta-EXPECTED_NUMBER_OF_VARIABLES:${EXPECTED_NUMBER_OF_VARIABLES}" \
          -h "x-goog-meta-EXPECTED_NUMBER_OF_DECISION_INSTANCES:${EXPECTED_NUMBER_OF_DECISION_INSTANCES}" \
          cp "./${SQL_DUMP_FILENAME}" gs://optimize-data/
      shell: bash
    - name: Upload docker logs
      uses: ./.github/actions/docker-logs
      if: always()
      with:
        archive_name: docker-logs.zip
