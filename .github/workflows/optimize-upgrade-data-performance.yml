name: Optimize Upgrade Data Performance Test

on:
  workflow_dispatch:
    inputs:
      sql_dump:
        description: SQL dump to use
        type: "choice"
        options:
          - "optimize_data-medium.sqlc"
          - "optimize_data-large.sqlc"
          - "optimize_data-stage.sqlc"
        default: "optimize_data-medium.sqlc"
        required: false
      cambpm_version:
        description: Camunda BPM version to use, defaults to reading it from pom.xml
        required: false
      es_version:
        description: Elasticsearch version to use, defaults to reading it from pom.xml
        required: false
      prev_es_version:
        description: Elasticsearch version to use, defaults to reading it from pom.xml
        required: false
      upgrade_timeout:
        description: Timeout for the upgrade stage to complete in minutes
        type: number
        default: 360
        required: false
  schedule:
    - cron: 0 4 * * 1-5

jobs:
  upgrade-data-performance:
    runs-on: gcp-core-32-longrunning
    timeout-minutes: ${{ fromJson(inputs.upgrade_timeout || 360) }}

    steps:
      - uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29 # v4

      - name: Setup Maven
        uses: ./.github/actions/setup-maven
        with:
          secrets: ${{ toJSON(secrets) }}

      - name: Login to Harbor registry
        uses: ./.github/actions/login-registry
        with:
          secrets: ${{ toJSON(secrets) }}

      - name: Login to Google Cloud
        uses: ./.github/actions/login-gcloud
        with:
          secrets: ${{ toJSON(secrets) }}

      - name: Import secrets
        id: secrets
        uses: hashicorp/vault-action@d1720f055e0635fd932a1d2a48f87a666a57906c # v3.0.0
        with:
          url: ${{ secrets.VAULT_ADDR }}
          method: approle
          roleId: ${{ secrets.VAULT_ROLE_ID }}
          secretId: ${{ secrets.VAULT_SECRET_ID }}
          secrets: |
            secret/data/products/optimize/ci/camunda-optimize SLACK_BOT_URL;

      - name: "Read pom.xml file"
        id: "pom-info"
        uses: YunaBraska/java-info-action@main

      - name: Start Postgress
        uses: ./.github/actions/compose
        with:
          compose_file: ${{ github.workspace }}/.github/actions/compose/docker-compose.postgresql.yml
          project_name: postgres
        env:
          POSTGRES_CPUS: 4

      - name: Download and restore dump
        uses: ./.github/actions/restore-dump
        with:
          sql_dump: ${{ inputs.sql_dump || 'optimize_data-medium.sqlc' }}

      - name: Start Cambpm
        uses: ./.github/actions/compose
        with:
          compose_file: ${{ github.workspace }}/.github/actions/compose/docker-compose.cambpm-dbdriver.yml
          project_name: cambpm
        env:
          CAMBPM_VERSION: ${{ inputs.cambpm_version || steps.pom-info.outputs.x_camunda_engine_version }}
          CAMBPM_JVM_MEMORY: 6

      # done as it used for mounting and exchanging the backup between the 2 different elastic instances
      - name: Change current directory permissions
        run: |
          sudo chmod -R 777 ./

      - name: Start Elastic - Old
        uses: ./.github/actions/compose
        with:
          compose_file: ${{ github.workspace }}/.github/actions/compose/docker-compose.elasticsearch-ipclock.yml
          project_name: elasticsearch-old
        env:
          ELASTIC_VERSION: ${{ inputs.prev_es_version || steps.pom-info.outputs.x_previous_optimize_elasticsearch_version }}
          ELASTIC_JVM_MEMORY: 12
          ELASTIC_HTTP_PORT: 9250

      - name: Start Elastic - New
        uses: ./.github/actions/compose
        with:
          compose_file: ${{ github.workspace }}/.github/actions/compose/docker-compose.elasticsearch-ipclock.yml
          project_name: elasticsearch-new
        env:
          ELASTIC_VERSION: ${{ inputs.es_version || steps.pom-info.outputs.x_elasticsearch_test_version }}
          ELASTIC_JVM_MEMORY: 12
          ELASTIC_HTTP_PORT: 9200

      - name: Install
        uses: ./.github/actions/run-maven
        with:
          parameters: -DskipTests -Dskip.fe.build -Dskip.docker clean install -B

      - name: Performance test
        uses: ./.github/actions/run-maven
        with:
          parameters: -Pupgrade-es-schema-tests -pl optimize/qa/upgrade-tests clean verify
          threads: 5

      - name: Pull Indices
        if: always()
        run: |
          curl localhost:9250/_cat/indices?v
          curl localhost:9200/_cat/indices?v

      - name: Post results on slack
        if: failure() && github.event_name != 'schedule'
        uses: ./.github/actions/notify-on-slack
        with:
          slack_webhook_url: ${{ steps.secrets.outputs.SLACK_BOT_URL}}
          status: ${{ job.status }}

      - name: Docker log dump
        uses: ./.github/actions/docker-logs
        if: always()
        with:
          archive_name: upgrade-data-performance-docker-logs

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # v4
        with:
          name: upgrade-data-performance-tests-logs
          path: |
            ./optimize/qa/upgrade-tests/target/**/*.log
          retention-days: 7
          if-no-files-found: ignore
